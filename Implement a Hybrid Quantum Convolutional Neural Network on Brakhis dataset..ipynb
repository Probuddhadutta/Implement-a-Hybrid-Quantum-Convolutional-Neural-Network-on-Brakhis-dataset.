{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMfJzARZlONIyGNqkoBAL/Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import time\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import os\n","\n","def train_network(net = None, train_set = None, val_set = None, device = None,\n","epochs = 10, bs = 20, optimizer = None, criterion = None):  # outdir = None, file_prefix = None):\n","\n","    train_loader = DataLoader(train_set, batch_size=bs, shuffle=True)\n","    val_loader = DataLoader(val_set, batch_size=bs, shuffle=True)\n","\n","    net = net.to(device)\n","\n","    tr_losses = []\n","    val_losses = []\n","    tr_accs = []\n","    val_accs = []\n","\n","    for epoch in range(epochs):\n","        t1 = time.time()\n","        net.train()\n","        tr_loss = 0\n","\n","        y_trues = []\n","        y_preds = []\n","\n","        for i, sampled_batch in enumerate(train_loader):\n","\n","            t2 = time.time()\n","\n","            data = sampled_batch['feature']\n","            y = sampled_batch['label'].squeeze()\n","\n","            data = data.type(torch.FloatTensor)\n","            y = y.type(torch.LongTensor)\n","\n","            data = data.to(device)\n","            y = y.to(device)\n","\n","            optimizer.zero_grad()\n","            output = net(data)\n","\n","            loss = criterion(output,y)\n","\n","            loss.backward()\n","            optimizer.step()\n","            #print(net.ql1.weights.grad)\n","            tr_loss = tr_loss + loss.data.cpu().numpy()\n","\n","            y_trues += y.cpu().numpy().tolist()\n","            y_preds += output.data.cpu().numpy().argmax(axis=1).tolist()\n","\n","            print('batch({}):{:.4f}'.format(i,time.time()-t2))\n","\n","        tr_acc = accuracy_score(y_trues, y_preds)\n","        tr_accs.append(tr_acc)\n","        tr_loss = tr_loss/(i+1)\n","        tr_losses.append(tr_loss)\n","\n","        cnf = confusion_matrix(y_trues, y_preds)\n","        print(cnf)\n","\n","        print('Epoch:{}, TR_Loss: {:.4f}, TR_Acc: {:.4f}'.format(epoch, tr_loss, tr_acc))\n","\n","        net.eval()\n","        val_loss = 0\n","\n","        y_trues = []\n","        y_preds = []\n","\n","        for i, sampled_batch in enumerate(val_loader):\n","            data = sampled_batch['feature']\n","            y = sampled_batch['label'].squeeze()\n","\n","            data = data.type(torch.FloatTensor)\n","            y = y.type(torch.LongTensor)\n","\n","            data = data.to(device)\n","            y = y.to(device)\n","\n","            with torch.no_grad():\n","                output = net(data)\n","\n","            loss = criterion(output,y)\n","            val_loss = val_loss + loss.data.cpu().numpy()\n","\n","            y_trues += y.cpu().numpy().tolist()\n","            y_preds += output.data.cpu().numpy().argmax(axis=1).tolist()\n","\n","        val_acc = accuracy_score(y_trues, y_preds)\n","        val_accs.append(val_acc)\n","        val_loss = val_loss/(i+1)\n","        val_losses.append(val_loss)\n","\n","        cnf = confusion_matrix(y_trues, y_preds)\n","        print(cnf)\n","\n","        print('Epoch: {} VAL_Loss: {:.4f}, VAL_Acc: {:.4f}'.format(epoch, val_loss, val_acc))\n","        print('Time for Epoch ({}): {:.4f}'.format(epoch, time.time()-t1))\n","\n","    #save model and results\n","    # os.makedirs(outdir, exist_ok = True)\n","    # torch.save(net.state_dict(), outdir + '/' + file_prefix + '_model')\n","    # np.save(outdir + '/' + file_prefix + '_training_loss.npy', tr_losses)\n","    # np.save(outdir + '/' + file_prefix + '_validation_loss.npy', val_losses)\n","    # np.save(outdir + '/' + file_prefix + '_training_accuracy.npy', tr_accs)\n","    # np.save(outdir + '/' + file_prefix + '_validation_accuracy.npy', val_accs)"],"metadata":{"id":"ysb4njNUyhFm","executionInfo":{"status":"ok","timestamp":1732764161523,"user_tz":-330,"elapsed":386,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","torch.manual_seed(0)\n","\n","n_class = 3\n","n_features = 196\n","\n","class Net(nn.Module):\n","    # define nn\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv = nn.Conv2d(1, 4, 2, stride = 2)\n","        # self.lr1 = nn.LeakyReLU(0.1)\n","        # self.ln1 = nn.LayerNorm(32, elementwise_affine=True)\n","        self.fc1 = nn.Linear(4*7*7, 6)\n","        self.fc2 = nn.Linear(6, 3)\n","\n","    def forward(self, X):\n","        bs = X.shape[0]\n","        X = X.view(X.shape[0], 1, 14, 14)\n","        X = self.conv(X)\n","        X = F.relu(X)\n","        X = X.view(bs,-1)\n","        X = self.fc1(X)\n","        X = F.relu(X)\n","        X = self.fc2(X)\n","        return X"],"metadata":{"id":"a8wUlEZIytGx","executionInfo":{"status":"ok","timestamp":1732764216114,"user_tz":-330,"elapsed":413,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install pennylane # This line installs PennyLane\n","\n","# ipython-input-3-dd0c84b8a7e9\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","import time\n","import numpy as np\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import os\n","\n","# ... (Rest of the code in ipython-input-3-dd0c84b8a7e9 remains unchanged) ...\n","\n","# ipython-input-4-dd0c84b8a7e9\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# ... (Rest of the code in ipython-input-4-dd0c84b8a7e9 remains unchanged) ...\n","\n","# ipython-input-5-dd0c84b8a7e9\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","import pennylane as qml # This import should now work\n","from math import ceil\n","from math import pi\n","\n","torch.manual_seed(0)\n","\n","n_qubits = 4\n","n_layers = 1\n","n_class = 3\n","n_features = 196\n","image_x_y_dim = 14\n","kernel_size = n_qubits\n","stride = 2\n","\n","dev = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","\n","def circuit(inputs, weights):\n","    var_per_qubit = int(len(inputs) / n_qubits) + 1\n","    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit / 2)\n","    for qub in range(n_qubits):\n","        qml.Hadamard(wires=qub)\n","        for i in range(var_per_qubit):\n","            if (qub * var_per_qubit + i) < len(inputs):\n","                exec('qml.{}({}, wires = {})'.format(encoding_gates[i], inputs[qub * var_per_qubit + i], qub))\n","            else:  # load nothing\n","                pass\n","\n","    for l in range(n_layers):\n","        for i in range(n_qubits):\n","            qml.CRZ(weights[l, i], wires=[i, (i + 1) % n_qubits])\n","            # qml.CNOT(wires = [i, (i + 1) % n_qubits])\n","        for j in range(n_qubits, 2 * n_qubits):\n","            qml.RY(weights[l, j], wires=j % n_qubits)\n","\n","    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","    return _expectations\n","    # return qml.expval(qml.PauliZ(0))\n","\n","\n","class Quanv2d(nn.Module):\n","    def __init__(self, kernel_size=None, stride=None):\n","        super(Quanv2d, self).__init__()\n","        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n","        qnode = qml.QNode(circuit, dev, interface='torch', diff_method='best')\n","        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","\n","    def forward(self, X):\n","        assert len(X.shape) == 4\n","        bs = X.shape[0]\n","        XL = []\n","        for i in range(0, X.shape[2] - 2, stride):\n","            for j in range(0, X.shape[3] - 2, stride):\n","                XL.append(self.ql1(torch.flatten(X[:, :, i:i + kernel_size, j:j + kernel_size], start_dim=1)))\n","        X = torch.cat(XL, dim=1).view(bs,4,6,6)\n","        return X\n","\n","\n","class Net(nn.Module):\n","    # define nn\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.ql1 = Quanv2d(kernel_size=kernel_size, stride=stride)\n","        self.conv1 = nn.Conv2d(4,16,3,stride=1)\n","        self.fc1 = nn.Linear(16*4*4, n_class * 2)\n","        self.lr1 = nn.LeakyReLU(0.1)\n","        self.fc2 = nn.Linear(n_class * 2, n_class)\n","\n","    def forward(self, X):\n","        bs = X.shape[0]\n","        X = X.view(bs, 1, image_x_y_dim, image_x_y_dim)\n","        X = self.ql1(X)\n","        X = self.lr1(self.conv1(X))\n","        X = X.view(bs,-1)\n","        X = self.fc1(X)\n","        X = self.lr1(X)\n","        X = self.fc2(X)\n","        return X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdEMQqDxy9_7","executionInfo":{"status":"ok","timestamp":1732764313108,"user_tz":-330,"elapsed":10000,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}},"outputId":"e963fa2b-a228-4908-a285-4984abef9b20"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pennylane\n","  Downloading PennyLane-0.39.0-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n","Collecting rustworkx>=0.14.0 (from pennylane)\n","  Downloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n","Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n","Collecting appdirs (from pennylane)\n","  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n","Collecting autoray>=0.6.11 (from pennylane)\n","  Downloading autoray-0.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n","Collecting pennylane-lightning>=0.39 (from pennylane)\n","  Downloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n","Downloading PennyLane-0.39.0-py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading autoray-0.7.0-py3-none-any.whl (930 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.0/930.0 kB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PennyLane_Lightning-0.39.0-cp310-cp310-manylinux_2_28_x86_64.whl (1.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rustworkx-0.15.1-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n","Installing collected packages: appdirs, rustworkx, autoray, pennylane-lightning, pennylane\n","Successfully installed appdirs-1.4.4 autoray-0.7.0 pennylane-0.39.0 pennylane-lightning-0.39.0 rustworkx-0.15.1\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pennylane as qml\n","from math import ceil\n","from math import pi\n","\n","torch.manual_seed(0)\n","\n","n_qubits = 4\n","n_layers = 1\n","n_class = 3\n","n_features = 196\n","image_x_y_dim = 14\n","kernel_size = n_qubits\n","stride = 2\n","\n","dev = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","\n","def circuit(inputs, weights):\n","    var_per_qubit = int(len(inputs) / n_qubits) + 1\n","    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit / 2)\n","    for qub in range(n_qubits):\n","        qml.Hadamard(wires=qub)\n","        for i in range(var_per_qubit):\n","            if (qub * var_per_qubit + i) < len(inputs):\n","                exec('qml.{}({}, wires = {})'.format(encoding_gates[i], inputs[qub * var_per_qubit + i], qub))\n","            else:  # load nothing\n","                pass\n","\n","    for l in range(n_layers):\n","        for i in range(n_qubits):\n","            qml.CRZ(weights[l, i], wires=[i, (i + 1) % n_qubits])\n","            # qml.CNOT(wires = [i, (i + 1) % n_qubits])\n","        for j in range(n_qubits, 2 * n_qubits):\n","            qml.RY(weights[l, j], wires=j % n_qubits)\n","\n","    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","    return _expectations\n","    # return qml.expval(qml.PauliZ(0))\n","\n","\n","class Quanv2d(nn.Module):\n","    def __init__(self, kernel_size=None, stride=None):\n","        super(Quanv2d, self).__init__()\n","        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n","        qnode = qml.QNode(circuit, dev, interface='torch', diff_method='best')\n","        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","\n","    def forward(self, X):\n","        assert len(X.shape) == 4 # (bs, c, w, h)\n","        bs = X.shape[0]\n","        XL = []\n","        for i in range(0, X.shape[2] - 2, stride):\n","            for j in range(0, X.shape[3] - 2, stride):\n","                XL.append(self.ql1(torch.flatten(X[:, :, i:i + kernel_size, j:j + kernel_size], start_dim=1)))\n","        X = torch.cat(XL, dim=1).view(bs,4,6,6)\n","        return X\n","\n","class Inception(nn.Module):\n","    def __init__(self,in_channels):\n","        super(Inception, self).__init__()\n","\n","        self.branchClassic_1 = nn.Conv2d(in_channels,4,kernel_size=1,stride=1)\n","        self.branchClassic_2 = nn.Conv2d(4,8,kernel_size=4,stride=2)\n","\n","        self.branchQuantum = Quanv2d(kernel_size=4,stride=2)\n","\n","    def forward(self,x):\n","        classic = self.branchClassic_1(x)\n","        classic = self.branchClassic_2(classic)\n","\n","        quantum = self.branchQuantum(x)\n","\n","        outputs = [classic,quantum]\n","        return torch.cat(outputs,dim=1)\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.incep = Inception(in_channels=1)\n","        self.fc1 = nn.Linear(12*6*6,32)\n","        self.fc2 = nn.Linear(20,10)\n","        self.lr = nn.LeakyReLU(0.1)\n","\n","    def forward(self,x):\n","        bs = x.shape[0]\n","        x = x.view(bs,1,14,14)\n","        x = self.incep(x)\n","        x = self.lr(x)\n","\n","        x = x.view(bs,-1)\n","        x = self.lr(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"p3_ENyvIzPjt","executionInfo":{"status":"ok","timestamp":1732764353066,"user_tz":-330,"elapsed":405,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import pennylane as qml\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","torch.manual_seed(0)\n","\n","n_qubits = 4\n","n_layers = 1\n","dev = qml.device('default.qubit', wires=n_qubits)\n","\n","def circuit(inputs, weights):\n","    for qub in range(n_qubits):\n","        qml.Hadamard(wires=qub)\n","        qml.RY(inputs[qub], wires=qub)\n","        # qml.RY(inputs[qub], wires=qub)\n","\n","    for layer in range(n_layers):\n","        for i in range(n_qubits):\n","            qml.CRZ(weights[layer,i], wires=[i, (i + 1) % n_qubits])\n","        for j in range(n_qubits,2*n_qubits):\n","            qml.RY(weights[layer,j], wires=j % n_qubits)\n","\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","\n","class Quanv2d(nn.Module):\n","    def __init__(self, kernel_size):\n","        super(Quanv2d, self).__init__()\n","        weight_shapes = {\"weights\": (n_layers,2*n_qubits)}\n","        qnode = qml.QNode(circuit, dev, interface='torch', diff_method=\"best\")\n","        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n","        self.kernel_size = kernel_size\n","        #self.stride = stride\n","\n","    def forward(self, x):\n","        assert len(x.shape) == 4  # (bs, c, w, h)\n","        bs = x.shape[0]\n","        # side_len = X.shape[2] - self.kernel_size + 1  # *******\n","        x_lst = []\n","        for i in range(0, x.shape[2]-1,2):\n","            for j in range(0, x.shape[3]-1,2):\n","                x_lst.append(self.ql1(torch.flatten(x[:, :, i:i + self.kernel_size, j:j + self.kernel_size], start_dim=1)))\n","        x = torch.cat(x_lst,dim=1).view(bs,4,7,7)\n","        return x\n","\n","class Inception(nn.Module):\n","    def __init__(self,in_channels):\n","        super(Inception, self).__init__()\n","\n","        self.branchClassic_1 = nn.Conv2d(in_channels,4,kernel_size=1,stride=1)\n","        self.branchClassic_2 = nn.Conv2d(4,8,kernel_size=4,stride=2,padding=1)\n","\n","        self.branchQuantum = Quanv2d(kernel_size=2)\n","\n","    def forward(self,x):\n","        classic = self.branchClassic_1(x)\n","        classic = self.branchClassic_2(classic)\n","\n","        quantum = self.branchQuantum(x)\n","\n","        outputs = [classic,quantum]\n","        return torch.cat(outputs,dim=1)\n","\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.incep = Inception(in_channels=1)\n","        self.fc1 = nn.Linear(12*7*7,32)\n","        self.fc2 = nn.Linear(32,10)\n","        self.lr = nn.LeakyReLU(0.1)\n","\n","    def forward(self,x):\n","        bs = x.shape[0]\n","        x = x.view(bs,1,14,14)\n","        x = self.incep(x)\n","        x = self.lr(x)\n","\n","        x = x.view(bs,-1)\n","        x = F.relu(self.fc1(x))\n","        x = self.fc2(x)\n","        return x"],"metadata":{"id":"ZcXKxLmezb3x","executionInfo":{"status":"ok","timestamp":1732764388947,"user_tz":-330,"elapsed":405,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import pennylane as qml\n","from math import ceil\n","from math import pi\n","\n","torch.manual_seed(0)\n","\n","n_qubits = 4\n","n_layers = 1\n","n_class = 3\n","n_features = 196\n","image_x_y_dim = 14\n","kernel_size = n_qubits\n","stride = 2\n","\n","dev = qml.device(\"default.qubit\", wires = n_qubits)\n","\n","def circuit(inputs, weights):\n","    var_per_qubit = int(len(inputs)/n_qubits) + 1\n","    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit/2)\n","    for qub in range(n_qubits):\n","        qml.Hadamard(wires = qub)\n","        for i in range(var_per_qubit):\n","            if (qub * var_per_qubit + i) < len(inputs):\n","                exec('qml.{}({}, wires = {})'.format(encoding_gates[i], inputs[qub * var_per_qubit + i], qub))\n","            else: #load nothing\n","                pass\n","\n","    for l in range(n_layers):\n","        for i in range(n_qubits):\n","            qml.CRZ(weights[l, i], wires = [i, (i + 1) % n_qubits])\n","            #qml.CNOT(wires = [i, (i + 1) % n_qubits])\n","        for j in range(n_qubits, 2*n_qubits):\n","            qml.RY(weights[l, j], wires = j % n_qubits)\n","\n","    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","    return _expectations\n","    #return qml.expval(qml.PauliZ(0))\n","\n","class Quanv2d(nn.Module):\n","    def __init__(self, kernel_size = None, stride = None):\n","        super(Quanv2d, self).__init__()\n","        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n","        qnode = qml.QNode(circuit, dev, interface = 'torch', diff_method = 'best')\n","        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","\n","    def forward(self, X):\n","        assert len(X.shape) == 4 #(bs, c, w, h)\n","        XL = []\n","        for i in range(0, X.shape[2]-2, stride):\n","            for j in range(0, X.shape[3]-2, stride):\n","                XL.append(self.ql1(torch.flatten(X[:, :, i:i+kernel_size, j:j+kernel_size], start_dim = 1)))\n","        X = torch.cat(XL, dim = 1)\n","        return X\n","\n","class Net(nn.Module):\n","    # define nn\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.ql1 = Quanv2d(kernel_size = kernel_size, stride = stride)\n","\n","        self.fc1 = nn.Linear(4*6*6, n_class * 2)\n","        self.lr1 = nn.LeakyReLU(0.1)\n","        self.fc2 = nn.Linear(n_class * 2, n_class)\n","\n","    def forward(self, X):\n","\n","        bs = X.shape[0]\n","        X = X.view(bs, 1, image_x_y_dim, image_x_y_dim)\n","        X = self.ql1(X)\n","\n","        X = self.fc1(X)\n","        X = self.lr1(X)\n","        X = self.fc2(X)\n","        return X\n","\n","# if __name__ == '__main__':\n","#     network = Net()\n","#     random_input = torch.rand(1, n_features)\n","#     print(network(random_input))\n","#\n","#     q1 = Quanv2d(kernel_size = kernel_size, stride = stride)\n","#     random_input = random_input.view(1, image_x_y_dim, image_x_y_dim)\n","#     print(q1(random_input))"],"metadata":{"id":"tph3VD4wzkn6","executionInfo":{"status":"ok","timestamp":1732764409920,"user_tz":-330,"elapsed":393,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import pennylane as qml\n","from math import ceil\n","from math import pi\n","\n","torch.manual_seed(0)\n","\n","n_qubits = 4\n","n_layers = 1\n","n_class = 3\n","n_features = 196\n","image_x_y_dim = 14\n","kernel_size = n_qubits\n","stride = 2\n","\n","dev = qml.device(\"default.mixed\", wires=n_qubits)\n","\n","\n","def circuit(inputs, weights):\n","    var_per_qubit = int(len(inputs) / n_qubits) + 1\n","    encoding_gates = ['RZ', 'RY'] * ceil(var_per_qubit / 2)\n","    for qub in range(n_qubits):\n","        qml.Hadamard(wires=qub)\n","        for i in range(var_per_qubit):\n","            if (qub * var_per_qubit + i) < len(inputs):\n","                exec('qml.{}({}, wires = {})'.format(encoding_gates[i], inputs[qub * var_per_qubit + i], qub))\n","            else:  # load nothing\n","                pass\n","\n","    for l in range(n_layers):\n","        for i in range(n_qubits):\n","            qml.CRZ(weights[l, i], wires=[i, (i + 1) % n_qubits])\n","            # qml.CNOT(wires = [i, (i + 1) % n_qubits])\n","        for j in range(n_qubits, 2 * n_qubits):\n","            qml.RY(weights[l, j], wires=j % n_qubits)\n","\n","    _expectations = [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","    return _expectations\n","    # return qml.expval(qml.PauliZ(0))\n","\n","\n","class Quanv2d(nn.Module):\n","    def __init__(self, kernel_size=None, stride=None):\n","        super(Quanv2d, self).__init__()\n","        weight_shapes = {\"weights\": (n_layers, 2 * n_qubits)}\n","        qnode = qml.QNode(circuit, dev, interface='torch', diff_method='best')\n","        self.ql1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","\n","    def forward(self, X):\n","        assert len(X.shape) == 4  # (bs, c, w, h)\n","        XL = []\n","        for i in range(0, X.shape[2] - 2, stride):\n","            for j in range(0, X.shape[3] - 2, stride):\n","                XL.append(self.ql1(torch.flatten(X[:, :, i:i + kernel_size, j:j + kernel_size], start_dim=1)))\n","        X = torch.cat(XL, dim=1)\n","        return X\n","\n","\n","class Net(nn.Module):\n","    # define nn\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.ql1 = Quanv2d(kernel_size=kernel_size, stride=stride)\n","\n","        self.fc1 = nn.Linear(4 * 6 * 6, n_class * 2)\n","        self.lr1 = nn.LeakyReLU(0.1)\n","        self.fc2 = nn.Linear(n_class * 2, n_class)\n","\n","    def forward(self, X):\n","        bs = X.shape[0]\n","        X = X.view(bs, 1, image_x_y_dim, image_x_y_dim)\n","        X = self.ql1(X)\n","\n","        X = self.fc1(X)\n","        X = self.lr1(X)\n","        X = self.fc2(X)\n","        return X\n"],"metadata":{"id":"xCEz-I0rzpu3","executionInfo":{"status":"ok","timestamp":1732764436623,"user_tz":-330,"elapsed":430,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["pip install pennylane tensorflow keras qiskit\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gooln_FazwQB","executionInfo":{"status":"ok","timestamp":1732764484693,"user_tz":-330,"elapsed":12982,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}},"outputId":"1f97dc20-c008-4c1e-bdb7-26181e24bd95"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.39.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Collecting qiskit\n","  Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n","Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n","Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n","Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.7.0)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n","Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.39.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n","Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n","Collecting dill>=0.3 (from qiskit)\n","  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n","Collecting stevedore>=3.0.0 (from qiskit)\n","  Downloading stevedore-5.4.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting symengine<0.14,>=0.11 (from qiskit)\n","  Downloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n","Collecting pbr>=2.0.0 (from stevedore>=3.0.0->qiskit)\n","  Downloading pbr-6.1.0-py2.py3-none-any.whl.metadata (3.4 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Downloading qiskit-1.2.4-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.9-py3-none-any.whl (119 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading stevedore-5.4.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading symengine-0.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pbr-6.1.0-py2.py3-none-any.whl (108 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.5/108.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: symengine, pbr, dill, stevedore, qiskit\n","Successfully installed dill-0.3.9 pbr-6.1.0 qiskit-1.2.4 stevedore-5.4.0 symengine-0.13.0\n"]}]},{"cell_type":"code","source":["import pennylane as qml\n","from pennylane import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n"],"metadata":{"id":"h4xHqiE6z48K","executionInfo":{"status":"ok","timestamp":1732764504554,"user_tz":-330,"elapsed":10070,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["n_qubits = 4\n","dev = qml.device('default.qubit', wires=n_qubits)\n","\n","@qml.qnode(dev)\n","def quantum_circuit(inputs):\n","    for i in range(n_qubits):\n","        qml.RX(inputs[i], wires=i)\n","    for i in range(n_qubits - 1):\n","        qml.CNOT(wires=[i, i + 1])\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n"],"metadata":{"id":"DVgbgzTpz-gO","executionInfo":{"status":"ok","timestamp":1732764532248,"user_tz":-330,"elapsed":390,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class QuantumLayer(layers.Layer):\n","    def __init__(self, n_qubits, **kwargs):\n","        super(QuantumLayer, self).__init__(**kwargs)\n","        self.n_qubits = n_qubits\n","\n","    def call(self, inputs):\n","        batch_size = tf.shape(inputs)[0]\n","        outputs = []\n","        for i in range(batch_size):\n","            quantum_output = quantum_circuit(inputs[i])\n","            outputs.append(quantum_output)\n","        return tf.stack(outputs)\n"],"metadata":{"id":"uj9I04Sg0Hme","executionInfo":{"status":"ok","timestamp":1732764542701,"user_tz":-330,"elapsed":658,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["!pip install pennylane tensorflow keras qiskit\n","\n","import pennylane as qml\n","from pennylane import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow import keras\n","import tensorflow_datasets as tfds\n","\n","\n","# Load the Brakhis dataset\n","# Download the dataset from a trusted source\n","# and replace 'path/to/brakhis/dataset' with the actual path\n","\n","# Assuming the Brakhis dataset is preprocessed and loaded as NumPy arrays:\n","# x_train: training images\n","# y_train: training labels (0 for benign, 1 for malignant)\n","# x_test: testing images\n","# y_test: testing labels\n","\n","# Preprocess data (adjust according to your data format)\n","# For example:\n","# x_train = x_train.astype('float32') / 255.0\n","# x_test = x_test.astype('float32') / 255.0\n","\n","# Add channel dimension (if necessary)\n","# x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n","# x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n","\n","\n","\n","# Define the quantum circuit\n","n_qubits = 4\n","dev = qml.device('default.qubit', wires=n_qubits)\n","\n","@qml.qnode(dev)\n","def quantum_circuit(inputs):\n","    for i in range(n_qubits):\n","        qml.RX(inputs[i], wires=i)\n","    for i in range(n_qubits - 1):\n","        qml.CNOT(wires=[i, i + 1])\n","    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n","\n","# Define the quantum layer\n","class QuantumLayer(layers.Layer):\n","    def __init__(self, n_qubits, **kwargs):\n","        super(QuantumLayer, self).__init__(**kwargs)\n","        self.n_qubits = n_qubits\n","\n","    def call(self, inputs):\n","        # Use tf.map_fn to apply the quantum circuit to each element in the batch\n","        # This avoids using a Python loop with a symbolic tensor\n","        quantum_output = tf.map_fn(lambda x: quantum_circuit(x[:self.n_qubits]), inputs)\n","        return quantum_output\n","\n","# Define the hybrid QCNN model\n","def create_hybrid_qcnn(input_shape):\n","    model = models.Sequential([\n","        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n","        layers.MaxPooling2D(pool_size=(2, 2)),\n","        layers.Flatten(),\n","        QuantumLayer(n_qubits),\n","        layers.Dense(1, activation='sigmoid')  # Adjust output units for Brakhis dataset (binary classification)\n","    ])\n","    return model\n","\n","# Create the model\n","# Assuming x_train.shape[1:] provides the image dimensions\n","# model = create_hybrid_qcnn(x_train.shape[1:])\n","\n","\n","# Compile the model\n","# model.compile(optimizer='adam',\n","#               loss='binary_crossentropy',  # Use binary_crossentropy for Brakhis dataset\n","#               metrics=['accuracy'])\n","\n","# Train the model\n","# model.fit(x_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t47YrXnJ08WP","executionInfo":{"status":"ok","timestamp":1732764852186,"user_tz":-330,"elapsed":9184,"user":{"displayName":"Probuddha Dutta (Rick)","userId":"03898441044073811325"}},"outputId":"b8f02616-9f49-404b-8d28-562a24e00846"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pennylane in /usr/local/lib/python3.10/dist-packages (0.39.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n","Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.4)\n","Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.4.2)\n","Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.15.1)\n","Requirement already satisfied: autograd in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.7.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n","Requirement already satisfied: autoray>=0.6.11 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.7.0)\n","Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.5.0)\n","Requirement already satisfied: pennylane-lightning>=0.39 in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.39.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.12.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pennylane) (24.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n","Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n","Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.9)\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n","Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.4.0)\n","Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.13.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2024.8.30)\n","Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ikaeMSup1Tk6"},"execution_count":null,"outputs":[]}]}